
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Location Reporter</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
      background-color: #f0f2f5;
      margin: 0;
      padding: 20px;
      text-align: center;
    }

    h1 {
      font-size: 22px;
      color: #222;
      margin-top: 40px;
    }

    #recordBtn {
      background: none;
      border: none;
      margin-top: 30px;
      padding: 0;
      cursor: pointer;
    }

    #recordBtn img {
      width: 70px;
      height: 70px;
      border-radius: 14px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      transition: transform 0.2s ease;
    }

    #recordBtn img:hover {
      transform: scale(1.08);
    }

    #instructions {
      margin-top: 20px;
      font-size: 16px;
      color: #555;
      padding: 0 15px;
    }

    #status, #response {
      margin-top: 20px;
      font-size: 17px;
      color: #333;
      padding: 0 15px;
    }

    #audio {
      margin-top: 24px;
      width: 90%;
      max-width: 320px;
    }
  </style>
</head>
<body>
  <h1>üìç Voice Location Reporter</h1>
  <button id="recordBtn">
    <img src="barty_button.png" alt="Record Button" />
  </button>
  <p id="instructions">Tap the button to report or ask about a location.</p>
  <div id="status"></div>
  <div id="response"></div>
  <audio id="audio" controls hidden></audio>

  <script>
    const status = document.getElementById('status');
    const responseText = document.getElementById('response');
    const audioPlayer = document.getElementById('audio');
    const recordBtn = document.getElementById('recordBtn');

    recordBtn.addEventListener('click', startRecognition);

    function startRecognition() {
      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = 'en-US';
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        status.textContent = "üé§ Listening...";
      };

      recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        status.textContent = `üìù Heard: "${text}"`;
        sendText(text);
      };

      recognition.onerror = (event) => {
        status.textContent = `‚ùå Error: ${event.error}`;
      };

      recognition.start();
    }

    function sendText(userInput) {
      fetch('https://ubiquitous-octo-carnival-backend.onrender.com/process_text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({ text: userInput }),
        mode: 'cors'
      })
      .then(response => response.json())
      .then(data => {
        responseText.textContent = "ü§ñ " + data.reply;
        if (data.audio_url) {
          audioPlayer.src = data.audio_url;
          audioPlayer.hidden = false;
          audioPlayer.play();
        } else {
          audioPlayer.hidden = true;
        }
      })
      .catch(error => {
        console.error("Full fetch error:", error);
        responseText.textContent = "‚ùå Failed to get response. See console for details.";
        audioPlayer.hidden = true;
      });
    }
  </script>
</body>
</html>
